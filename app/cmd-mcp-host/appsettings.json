{
  "DefaultChatClient": "OpenAI",
  "ChatClients": [
    {
      "ProviderName": "Ionos",
      "Endpoint": "https://openai.inference.de-txl.ionos.com/v1",
      "DefaultModel": "meta-llama/Meta-Llama-3.1-405B-Instruct-FP8",
      "AvailableModels": [
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct",
        "meta-llama/Meta-Llama-3.1-405B-Instruct-FP8",
        "mistralai/Mistral-Nemo-Instruct-2407",
        "meta-llama/CodeLlama-13b-Instruct-hf",
        "mistralai/Mixtral-8x7B-Instruct-v0.1"
      ]
    },
    {
      "ProviderName": "Azure",
      "Endpoint": "https://evanto-ai-resource.services.ai.azure.com/models",
      "DefaultModel": "DeepSeek-R1",
      "AvailableModels": [
        "DeepSeek-R1"
      ]
    },
    {
      "ProviderName": "AzureOAI",
      "Endpoint": "https://svk-mcagu8ao-eastus2.cognitiveservices.azure.com/",
      "DefaultModel": "o4-mini",
      "AvailableModels": [
        "o4-mini",
        "o1"
      ]
    },
    {
      "ProviderName": "OpenAI",
      "Endpoint": "https://api.openai.com/v1",
      "DefaultModel": "o4-mini",
      "AvailableModels": [
        "o4-mini",
        "gpt-4.1-nano",
        "gpt-4.1-mini",
        "gpt-4.1",
        "o1",
        "o1-pro"
      ]
    },
    {
      "ProviderName": "LMStudio",
      "Endpoint": "http://localhost:1234/v1",
      "DefaultModel": "google/gemma-3-27b",
      "AvailableModels": [
        "google/gemma-3-27b"
      ]
    },
    {
      "ProviderName": "Ollama",
      "Endpoint": "http://localhost:11434",
      "DefaultModel": "qwen3:14b",
      "AvailableModels": [
        "qwen3:4b",
        "qwen3:14b",
        "gemma3:12b",
        "gemma3:27b"
      ]
    },
    {
      "ProviderName": "OllamaSharp",
      "Endpoint": "http://localhost:11434",
      "DefaultModel": "qwen3:14b",
      "AvailableModels": [
        "qwen3:4b",
        "qwen3:14b",
        "gemma3:12b",
        "gemma3:27b"
      ]
    }
  ],
  "McpServers": [
    {
      "Name": "Time MCP Server",
      "Command": "docker",
      "Arguments": [
        "run",
        "-i",
        "--rm",
        "mcp/time"
      ],
      "Enabled": true,
      "TimeoutSeconds": 30,
      "TransportType": "STDIO",
      "ToolTests": [
        {
          "ToolName": "get_current_time",
          "TestParameters": {
            "timezone": "Europe/Berlin"
          },
          "Enabled": true,
          "TimeoutSeconds": 15
        }
      ]
    },
    {
      "Name": "Evanto Support Requests MCP Server (STDIO)",
      "Command": "docker",
      "Arguments": [
        "run",
        "-it",
        "--rm",
        "--name stdio-mcp-server"
      ],
      "Enabled": false,
      "TimeoutSeconds": 30,
      "TransportType": "STDIO"
    },
    {
      "Name": "Evanto Support MCP Server (SSE)",
      "Url": "http://localhost:5561",
      "Enabled": true,
      "TimeoutSeconds": 30,
      "TransportType": "SSE",
      "ToolTests": [
        {
          "ToolName": "get_infos_from_documentation",
          "TestParameters": {
            "query": "Embeddings"
          },
          "Enabled": true,
          "TimeoutSeconds": 15
        },
        {
          "ToolName": "get_users_by_topic",
          "TestParameters": {
            "topic": "Technical"
          },
          "Enabled": true,
          "TimeoutSeconds": 10
        }
      ]
    }
  ],    
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft": "Warning",
      "System": "Warning"
    }
  },
  "Telemetry": {
    "Enabled": true,
    "EnableLogging": true,
    "ServiceName": "cmd-mcp-host",
    "ServiceVersion": "1.0.0",
    "EnableConsoleExporter": false,
    "EnableOtlpExporter": true,
    "OtlpEndpoint": "http://localhost:4317",
    "LogSensitiveData": false,
    "SamplingRatio": 1.0,
    "ActivitySources": [
      "Microsoft.Extensions.AI"
    ],
    "Headers": "x-otlp-api-key=65ED3495-EADC-470D-A342-6CFC9D2FA074"
  },
  "ConnectionStrings": {
    "SupportWizard": "Data Source=SupportWizard.db"
  },
    "UseConsoleLogging": false
}